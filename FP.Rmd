---
title: "PCA-Cluster ParityToolkit"
output: html_notebook
---


```{r, message=FALSE, results='hide'}
#setwd("/home/creatrol/GHack")
library(Hmisc); library(xlsx); library(dplyr); library(gtable); library(ggplot2); library(data.table)
```

## Load raw data and transformation considering currencies

```{r, warning=FALSE,message=FALSE}
############################################# Load data
Equities_data <- read.csv('data/Equities_data.csv',1)
Equities_metadata <- read.csv('data/Equities_metadata.csv',1)
Currencies_data <- read.csv('data/Currencies_data.csv',1)
Currencies_metadata <- read.csv('data/Currencies_metadata.csv',1)

######################### select open price as daily price & join datasets
Edata <- select(Equities_data, 1:3,8)
rm(Equities_data)
EdataM <- select(Equities_metadata, 1,3)
Cdata <- select(Currencies_data,1:3)
CdataM <- select(Currencies_metadata,1,3)
semiData <- left_join(Edata, EdataM)

######################### treat date
semiData$Date <- as.numeric(
  as.Date(as.character(semiData$Date), origin = '1899-12-30') - as.Date('1899-12-30'))
semiCurrencies <- left_join(Cdata, CdataM)
semiCurrencies$Date <- as.numeric(
  as.Date(as.character(semiCurrencies$Date), origin = '1899-12-30') - as.Date('1899-12-30'))
semiCurrencies <- semiCurrencies %>% rename(Rate = Open)%>%select(-1)

######################## use data.table to realize rolling for missing data
semiCurrenciesTable <- data.table(semiCurrencies)
rm(semiCurrencies)
semiDataTable <- data.table(semiData)
rm(semiData)
setkey(semiCurrenciesTable, CRNCY, Date)
setkey(semiDataTable, CRNCY, Date)
mydata <- semiCurrenciesTable[semiDataTable, roll = +Inf]
myData <- data.frame(mydata)
rm(mydata)

######################### focus on US market
myData <- myData %>% mutate(Rate2 = ifelse(grepl("_US_",as.character(Ticker)),1,Rate)) %>% 
  mutate(Price = Open/Rate2) %>%
  select(Ticker, Price, Date, Market.Cap)
finalOut <- myData[complete.cases(myData),]
USfinal <- finalOut[grepl("_US_",as.character(finalOut$Ticker)),]

######################### save data
save(USfinal, file = "USfinal.RData")
head(USfinal, 5)
rm(list = ls())
```


### using logathemic return & seperate into train test
```{r, warning=FALSE}
load("USfinal.RData")
rankOfMarket <- USfinal %>% filter(Date == max(Date)) %>% 
  arrange(desc(Market.Cap))

######################### choose how many tickers
nTickets <- 200
ticketChoice <- rankOfMarket$Ticker[1:nTickets]
USfinal <- USfinal %>% filter(Ticker %in% ticketChoice) %>% 
  select(-Market.Cap) %>% arrange(Date)
library(tidyr)
USOut <- spread(USfinal, Ticker,Price)
#USOut[complete.cases(USOut),]

######################### derive log return
USOutT1 <- USOut[2:nrow(USOut),-1]
USOutT <- USOut[1:(nrow(USOut)-1),-1]
USOutTime <- USOut[2:nrow(USOut),1]
USlogReturn <- log(USOutT1/USOutT)
USReturn <- cbind(USOutTime,USlogReturn)
USReturn[1:5,1:5]

######################## start day
beginning <- min(USReturn$USOutTime) + as.Date('1899-12-30')
```

## Build Clustering Function

```{r, warning=FALSE,message=FALSE}
clustering <- function(dataset, numCluster, clusterIteNum, removeOutliers = 0.999){
  
  ############################################ derive cor & cov
  UScorMatrix <- cor(dataset[,-1], use = "pairwise.complete.obs")
  UScovMatrix <- cov(dataset[,-1], use = "pairwise.complete.obs")
  
  ################# remove NAs for cor
  delete <- c()
  i <- 1
  for (col in 1:ncol(UScorMatrix)){
    if(sum(is.na(UScorMatrix[,col])) == nrow(UScorMatrix)){
      delete[i] <- col
      i = i+1 }}
  UScorMatrix <- UScorMatrix[-(delete),-(delete)]
  for (col in 1:ncol(UScorMatrix)){
    for (row in 1:nrow(UScorMatrix)){
      if (is.na(UScorMatrix[row,col]))
        UScorMatrix[row,col] <- 0 }}
  
  ################## remove NAs for cov
  delete <- c()
  i <- 1
  for (col in 1:ncol(UScovMatrix)){
    if(sum(is.na(UScovMatrix[,col])) == nrow(UScovMatrix)){
      delete[i] <- col
      i = i+1 }}
  UScovMatrix <- UScovMatrix[-(delete),-(delete)]
  for (col in 1:ncol(UScovMatrix)){
    for (row in 1:nrow(UScovMatrix)){
      if (is.na(UScovMatrix[row,col]))
        UScovMatrix[row,col] <- 0 }}

  ################## normalize the cov Matrix
#  outlierLine <- as.numeric(quantile(UScovMatrix,removeOutliers))
#  maxcov <- max(UScovMatrix, na.rm = TRUE)
#  mincov <- min(UScovMatrix, na.rm = TRUE)
#  normalcovMatrix <- (UScovMatrix - mincov) / (outlierLine - mincov)
#  for (i in 1:NROW(normalcovMatrix)){
#    for (j in 1:NCOL(normalcovMatrix)){
#      if (normalcovMatrix[i,j] > 1){
#        normalcovMatrix[i,j] <- 1
#  }}}
  
  ################# change the data storage type
  corDataFrame <- data.frame(UScorMatrix)
  covDataFrame <- data.frame(UScovMatrix)
#  covDataFrame <- data.frame(normalcovMatrix)
  
  ########################################## derive matrix for clustering

  for (i in 1:nrow(corDataFrame)){
    for (j in 1:ncol(corDataFrame)){
      corDataFrame[i,j] <- sqrt((1 - corDataFrame[i,j])/2)
    }}
  
  ######################################### PCA to choose initial centers
  pca.model <- prcomp(corDataFrame, center = FALSE, scale. = TRUE) 
  Rotation <- pca.model[2]
  pca.rotation1 <- Rotation[[1]][,1]
  positivePC <- pca.rotation1[order(abs(pca.rotation1), decreasing = TRUE)]
  centersNames <- names(positivePC[1:numCluster])
  
  ########################################## Clustering
  kcenters <- corDataFrame[centersNames, ]
  set.seed(2016)
  
  ###################### plot heatmap by ggplot
#  corDataFramePlot <- corDataFrame
#  corDataFramePlot$Name <- row.names(corDataFramePlot)
#  corDataFrame.m <- melt(corDataFramePlot)
  #flush.console()
#  g <- ggplot(data = corDataFrame.m, aes(x=Name, y=variable, fill=value)) + geom_tile() +
#    theme(axis.text = element_blank(), axis.title = element_blank())+
#      scale_fill_gradient(low = "white", high = "red")
#  print(g)
#  Sys.sleep(.09)
  
  ###################### Clustering
#  for (i in 1:clusterIteNum){
    
#    corCluster <- kmeans(corDataFrame, centers=kcenters, iter.max=1)
#    kcenters <- data.frame(corCluster$centers)
    
    ####################### reorder matrix
#    orderCluster <- corCluster$cluster[order(corCluster$cluster)]
#    nameList <- names(orderCluster)
#    newCorDataFrame <- corDataFrame[nameList,nameList]
    
#    if (i == clusterIteNum){
      ###################### plot heatmap
#      newCorDataFrame$Name <- row.names(newCorDataFrame)
#      newCorDataFrame.m <- melt(newCorDataFrame)
      #flush.console()
#      g <- ggplot(data = newCorDataFrame.m, aes(x=Name, y=variable, fill=value)) + geom_tile() +
#        theme(axis.text = element_blank(), axis.title = element_blank())
#      print(g)
#      Sys.sleep(.09)
#    }}
    ###################### inital heatmap
    tmap1 <- as.matrix(corDataFrame)
    map1 <- t(tmap1)
    
    ###################### clustering
    corCluster <- kmeans(corDataFrame, centers=kcenters, iter.max=clusterIteNum)
    kcenters <- data.frame(corCluster$centers)
    
    ####################### reorder matrix and heatmap
    orderCluster <- corCluster$cluster[order(corCluster$cluster)]
    clusterSize <- corCluster$size
    nameList <- names(orderCluster)
    newCorDataFrame <- corDataFrame[nameList,]
    newCorDataFrame <- newCorDataFrame[,nameList]
    tmap2 <- as.matrix(newCorDataFrame)
    map2 <- t(tmap2)
    
#   ####################### plot heatmap by ggplot
#    newCorDataFrame$Name <- nameList #row.names(newCorDataFrame)
#    newCorDataFrame.m <- melt(newCorDataFrame)
    #flush.console()
#    g <- ggplot(data = newCorDataFrame.m, aes(x=Name, y=variable, fill=value)) + geom_tile() +
#        theme(axis.text = element_blank(), axis.title = element_blank())+
#      scale_fill_gradient(low = "white", high = "red")
#    print(g)

  return(list(orderCluster,clusterSize,map1, map2))
}
```

# test

```{r}
library(caret)
library(stats)
startDate <- 31
marketValue <- 1
historyValue <- c(marketValue)
portfolio <- USReturn[1,-1]

change <- 0
endDate <- nrow(USReturn)
for (i in startDate:endDate){
  
  ########################################### build portfolio by history
  trainset <- USReturn[1:(i-1),]
  
  ################### Clustering
  numCluster <- 40
  clusterIteNum <- 500
  clusterResult <- clustering(trainset, numCluster, clusterIteNum)
  orderClusters <- clusterResult[[1]]
  clusterSize <- clusterResult[[2]]

  
  ################### change the portfolio
  ## randomly choose one equity from each cluster and ditribute the value equally
#  chosenEquity <- c()
#  for (equity in 1:numCluster){
#    chosenEquity <- c(chosenEquity, 
#                      names(orderClusters[orderClusters == equity])[1])
#  }
#  for (e in 1: ncol(portfolio)){
#    if (names(portfolio)[e] %in% chosenEquity){
      # distribute current market value among portfolio
#      portfolio[1,e] <- 1 / length(chosenEquity) * marketValue
#    }else{
#      portfolio[1,e] <- 0 
#    }
#  }

  ################### change the portfolio 2
  ## ditribute the value equally across the clusters and among in each clusters
  portfolio[1,] <- 0
  for (equity in 1: length(orderClusters)){
    portfolio[1, names(orderClusters)[equity]] <- 
      1 / numCluster / clusterSize[as.numeric(orderClusters[equity])] * marketValue
  }
  
  ################## record change of portfolio
  # change <- length(setdiff(chosenEquity,chosenEquityB))
  # chosenEquityB <- chosenEquity 
  # print(setdiff(chosenEquity,chosenEquityB))
  # print(i)
  # print(change)
  
  ########################################### get the current return
  flush.console()
  tmp <- USReturn[i,-1]
  tmp <- exp(tmp)
  todayValue <- sum(tmp * portfolio, na.rm = T)
  marketValue <- todayValue
  historyValue <- c(historyValue, marketValue)
  
  ################## plot
  time <- (startDate-1):i
  plot(time,historyValue,type = 'l')
  Sys.sleep(.01)
}
```

